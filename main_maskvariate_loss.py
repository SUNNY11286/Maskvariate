# -*- coding: utf-8 -*-

import numpy as np
import pandas as pd


import os
# from google.colab import drive
# drive.mount('/content/drive')

# !zip -r log.zip /content/drive/MyDrive/VDI

# pip install segmentation_models_3D

# pip install tensorflow_addons

# pip install tensorflow==2.12.0

# pip install tensorflow-probability==0.20.1

# import tensorflow as tf
# tf.__version__

from http import server
import nibabel as nib
import cv2
import gc
import os
os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'  # or any {'0', '1', '2'}
import tensorflow_addons as tfa
import numpy as np
import pandas as pd
from glob import glob
import tensorflow as tf
from tqdm.auto import tqdm
import keras.backend as K
import matplotlib.pyplot as plt
from sklearn.preprocessing import MinMaxScaler
from sklearn.model_selection import train_test_split
import segmentation_models_3D as sm
from sklearn.utils import shuffle

#%%
print("tensorflow version: ",tf.__version__)

# !nvidia-smi

# Create a MirroredStrategy.
strategy = tf.distribute.MirroredStrategy()
print("Number of devices: {}".format(strategy.num_replicas_in_sync))

""" # Brats - 19 """

# images_file19 = os.listdir("/content/drive/MyDrive/VDI/processed19_64/images/")
# masks_file19 = os.listdir("/content/drive/MyDrive/VDI/processed19_64/masks/")
# npy_images_path19 = [os.path.join("/content/drive/MyDrive/VDI/processed19_64/images/", img_file) for img_file in images_file19[:]]
# npy_masks_path19 = [os.path.join("/content/drive/MyDrive/VDI/processed19_64/masks/",mas_file) for mas_file in masks_file19[:]]

""" # BRats - 20"""

# images_file20 = os.listdir("/content/drive/MyDrive/VDI/processed20_64/images/")
# masks_file20 = os.listdir("/content/drive/MyDrive/VDI/processed20_64/masks/")
# npy_images_path20 = [os.path.join("/content/drive/MyDrive/VDI/processed20_64/images/", img_file) for img_file in images_file20[:]]
# npy_masks_path20 = [os.path.join("/content/drive/MyDrive/VDI/processed19_64/masks/",mas_file) for mas_file in masks_file20[:]]

""" # MDS task 01 data"""

images_file00 = os.listdir("/content/drive/MyDrive/VDI/processed_64/images/")
masks_file00 = os.listdir("/content/drive/MyDrive/VDI/processed_64/masks/")
npy_images_path00 = [os.path.join("/content/drive/MyDrive/VDI/processed_64/images/", img_file) for img_file in images_file00[:]]
npy_masks_path00 = [os.path.join("/content/drive/MyDrive/VDI/processed_64/masks/",mas_file) for mas_file in masks_file00[:]]

# images_file = os.listdir(path_img)
# masks_file = os.listdir(path_msk)
# npy_images_path = os.listdir(path_img)
# npy_masks_path = os.listdir(path_msk)

# print("image file is: %s" % images_file)
# print("masks file is: %s" % masks_file)
print('file loaded')

test_image = np.load(npy_images_path00[0])
print("test image: ",test_image.shape)

import numpy as np

def multivariate_cov(x,y):

  # find out covariance with respect  columns
  cov_mat = np.stack((x, y), axis = 0)
  return np.cov(cov_mat)[0][1]


x = [1.23, 2.12, 3.34, 4.5]
y = [2.56, 2.89, 3.76, 3.95]

multivariate_cov(x,y)

"""Mean Value thearom :

Mean between 2 values or ends...

![image.png](data:image/png;base64,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)

![image.png](data:image/png;base64,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)

![image.png](data:image/png;base64,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)
"""

def multivariate_mean(x,y):
  xm = np.mean(np.array(x))
  ym = np.mean(np.array(y))
  return np.mean([xm,ym])

x=[1,2]
y=[3]
print(multivariate_mean(x,y))

"""![image.png](data:image/png;base64,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)"""

# multivariate_norm(z_present)

import tensorflow_probability as tfp

from scipy.stats import multivariate_normal

def triplate_mean_lr(prev, pres, serv,lr):
  xm = tf.math.reduce_mean(prev)
  ym = tf.math.reduce_mean(pres)
  zm = tf.math.reduce_mean(serv)
  return lr * (tf.math.divide(tf.math.reduce_mean([xm,ym,zm]),tf.math.add(xm,ym,zm)))
  # pass

def contrastive_loss(z_prev,z_present,margin = 0.2, lr=1e-3):

     z_prev = tf.math.l2_normalize(z_prev)
    #  print('z_prev:',z_prev)
     z_present = tf.math.l2_normalize(z_present)
    #  print('z_present:',z_present)
     dis = tf.sqrt(tf.reduce_sum(tf.square(z_present - z_prev)))
    #  print('dis:',dis)
     dis = tf.math.maximum(dis, tf.keras.backend.epsilon()) # tf.keras.backend.epsilon()==1e-07
    #  print('dis:',dis)
     sqMar = tf.math.square(tf.math.maximum(margin - dis,tf.keras.backend.epsilon()))
    #  print('sqMar:',sqMar)

     sqpres = tf.math.square(z_present)
    #  print('sqpres:', sqpres)
     loss = tf.math.reduce_mean(z_prev*sqpres + z_present*sqMar)
    #  print('loss:',loss)
     loss = loss - (loss*lr)
    #  print('loss-loss*lr:',loss)
     lr = triplate_mean_lr(z_prev,z_present,lr)
    #  print('learning rate:',lr)
     srv = tf.sqrt(tf.reduce_sum(z_prev))
    #  print('srv:',srv)
     #srv = tf.math.l2_normalize(srv)
     srv = tf.math.log(srv)
    #  print('srv:',srv)
    #  print('loss/srv:',loss/srv)
    #  print('/////////////////////////////////////')
     return srv/loss, lr


# def contrastive_loss(prev, pres, serv, tau=1):
#     cosine_similarity = tf.keras.losses.CosineSimilarity(axis=1)
#     # cos_similarity=tf.reduce_sum(tf.multiply(normalize_a,normalize_b))
#     loss_con = - tf.math.log(tf.math.exp(cosine_similarity(pres, serv) / tau) / (tf.math.exp(cosine_similarity(pres, serv) / tau) + tf.math.exp(cosine_similarity(pres, prev) / tau)))
#     return loss_con

# def contrastive_loss(prev, pres, serv, tau=1):
#     cosine_similarity = tf.keras.losses.CosineSimilarity(axis=1)
#     numrator = tf.math.exp(cosine_similarity(pres, prev)/tau)
#     denom = tf.math.exp(cosine_similarity(pres, serv)/tau)
#     loss_con = - tf.math.log(numrator/denom)
#     # cos_similarity=tf.reduce_sum(tf.multiply(normalize_a,normalize_b))
#     # loss_con = - tf.math.log(tf.math.exp(cosine_similarity(pres, serv) / tau) / (tf.math.exp(cosine_similarity(pres, serv) / tau) + tf.math.exp(cosine_similarity(pres, prev) / tau)))
#     return loss_con

import math

# snbcd cmd c

"""# Final Code"""

# # LR = 0.00001
# LR = 1e-6
# optim = tf.keras.optimizers.Adam(LR)
# bs=5
# no_img = 360

# batch_size=2
# steps_per_epoch = 200//batch_size
# val_steps_per_epoch = 84//batch_size
# iou = sm.metrics.IOUScore(threshold=0.5)
# epochs = 100
# batch_size= bs
# past_model = None
# temperature = 0.5
# mu = 1
# num_comm = 1#5

# %%
def load_img(img_list):
    images=[]
    for i, image_name in enumerate(img_list):
        # print(i)
        # image = nib.load(image_name).get_fdata()
        image = np.load(image_name)
        images.append(image)
    images = np.asarray(images, dtype=np.float32)
    return(images)

npy_images_path00, npy_masks_path00 = shuffle(npy_images_path00,npy_masks_path00)

test_image = np.load(npy_images_path00[0])
print("test image: ",test_image.shape)




"""## 3D-UNet"""

class UNET3D(tf.keras.Model):
    def __init__(self,classes):
        super(UNET3D,self).__init__()
        self.classes = classes
        # self.encoder_rep = None # s

    #helper functions
    def conv3D(self,x,
               filters,
               filter_size,
               activation = 'relu'):
        out = tf.keras.layers.Conv3D(filters,(filter_size,filter_size,filter_size),padding = "same",use_bias=True )(x)
        batch_norm_ = tf.keras.layers.BatchNormalization()(out)
        conv_batch_norm_act = tf.keras.layers.Activation('relu')(batch_norm_)
        return out

    def upsampling3D(self,x,
                     filters,
                     filter_size,
                     stride =2,
                     activation = 'relu'):
        up_out = tf.keras.layers.Conv3DTranspose(filters,(filter_size,filter_size,filter_size),strides = (stride,stride,stride),padding = 'same')(x)
        batch_norm_ = tf.keras.layers.BatchNormalization()(up_out)
        return batch_norm_

    def concatenate(self,x1,x2):
        concat = tf.keras.layers.concatenate([x1,x2])
        return concat

    def max_pool3D(self, x, filter_size,stride, name = None):
        out = tf.keras.layers.MaxPooling3D((filter_size,filter_size,filter_size),strides = stride, name = name)(x)
        return out

    def downconv(self,x,filters, name = None):
        s1 = self.conv3D(x,filters,3)
        s2 = self.conv3D(s1,filters,3)
        return s2

    def upconv(self,x,
               filters,skip_connection):
        e1 = self.upsampling3D(x,filters,6)
        concat = self.concatenate(e1,skip_connection)
        #layer2
        conv1 = self.conv3D(concat,filters,3)
        #layer 3
        conv2 = self.conv3D(conv1,filters,3)
        return conv2

    def call(self):
        #input
        # inputs = tf.keras.layers.Input(shape = (128,128,128,1))
        inputs = tf.keras.layers.Input(shape = (64,64,64,1))
#         inputs = tf.keras.layers.Input(shape = (240,240,160,4))
        #encoder
        # print(inputs.shape)
        d1 = self.downconv(inputs,32)
        # print(d1.shape)
        m1 = self.max_pool3D(d1,filter_size = 2,stride = 2)
        # print(m1.shape)
        d2 = self.downconv(m1,64)
        m2 = self.max_pool3D(d2,filter_size = 2,stride = 2)
        d3 = self.downconv(m2,128)
        m3 = self.max_pool3D(d3,filter_size = 2,stride = 2)
        d4 = self.downconv(m3,256)
        m4 = self.max_pool3D(d4,filter_size =2,stride=2, name = "layer_before_output")
        # encoder_output = m4
        # print(encoder_output.shape)

        #bottleneck
        bridge1 = self.conv3D(m4,1024,3,1)
        bridge2 = self.conv3D(bridge1,1024,3,1)
        # self.encoder_rep = bridge # s

        #decoder
        # print("bridge2_shape = ",bridge2.shape)
        # print("d4_shape = ",d4.shape)
        u1 = self.upconv(bridge2,256,d4)
        u2 = self.upconv(u1,128,d3)
        u3 = self.upconv(u2,64,d2)
        u4 = self.upconv(u3,32,d1)

        #1x1 output
        logits = tf.keras.layers.Conv3D(self.classes,(1,1,1),padding = "same")(u4)
        logits = tf.nn.sigmoid(logits)

        #model
        model = tf.keras.Model(inputs = [inputs],outputs = [bridge2, logits])
        return model

unet_s = UNET3D(1)

class UNET3DClients(tf.keras.Model):
    def __init__(self,classes):
        super(UNET3DClients,self).__init__()
        self.classes = classes

    #helper functions
    def conv3D(self,x,
               filters,
               filter_size,
               activation = 'relu',name = None):
        out = tf.keras.layers.Conv3D(filters,(filter_size,filter_size,filter_size),padding = "same",name =name,use_bias = True)(x)
        batch_norm_ = tf.keras.layers.BatchNormalization()(out)
        conv_batch_norm_act = tf.keras.layers.Activation('relu')(batch_norm_)
        return out

    def upsampling3D(self,x,
                     filters,
                     filter_size,
                     stride =2,
                     activation = 'relu'):
        up_out = tf.keras.layers.Conv3DTranspose(filters,(filter_size,filter_size,filter_size),strides = (stride,stride,stride),padding = 'same')(x)
        batch_norm_ = tf.keras.layers.BatchNormalization()(up_out)
        return batch_norm_

    def concatenate(self,x1,x2):
        concat = tf.keras.layers.concatenate([x1,x2])
        return concat

    def max_pool3D(self, x, filter_size,stride, name = None):
        out = tf.keras.layers.MaxPooling3D((filter_size,filter_size,filter_size),strides = stride, name = name)(x)
        return out

    def downconv(self,x,filters,name = None):
        s1 = self.conv3D(x,filters,3, name =name )
        s2 = self.conv3D(s1,filters,3, name = name + "0")
        return s2

    def call(self):
        #input
        # inputse = tf.keras.layers.Input(shape = (128,128,128,1))
        inputse = tf.keras.layers.Input(shape = (64,64,64,1))
        #encoder
        d1e = self.downconv(inputse,32, name = "layer1")
        m1e = self.max_pool3D(d1e,filter_size = 2,stride = 2)
        d2e = self.downconv(m1e,64,  name = "layer2")
        m2e = self.max_pool3D(d2e,filter_size = 2,stride = 2)
        d3e = self.downconv(m2e,128, name = "layer3")
        m3e = self.max_pool3D(d3e,filter_size = 2,stride = 2)
        d4e = self.downconv(m3e,256, name = "layer4")
        m4e = self.max_pool3D(d4e,filter_size =2,stride=2)

        #model
        modele = tf.keras.Model(inputs = [inputse],outputs = [m4e])
        return modele
client_unet = UNET3DClients(1)

#dice Coeff
def dice_coef(y_true, y_pred, smooth=1.0):

    smooth = 1.0
    intersection = tf.reduce_sum(y_true * y_pred)
    union = tf.reduce_sum(y_true) + tf.reduce_sum(y_pred)
    dice = (2.0 * intersection + smooth) / (union + smooth)
    return dice

# Computing Precision
def precision(y_true, y_pred):

    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))
    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))
    precision = true_positives / (predicted_positives + K.epsilon())

    return precision

# Computing Sensitivity
def sensitivity(y_true, y_pred):

    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))
    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))

    return true_positives / (possible_positives + K.epsilon())

# Computing Specificity
def specificity(y_true, y_pred):

    true_negatives = K.sum(K.round(K.clip((1-y_true) * (1-y_pred), 0, 1)))
    possible_negatives = K.sum(K.round(K.clip(1-y_true, 0, 1)))

    return true_negatives / (possible_negatives + K.epsilon())

def mini_batches_( X, Y, batch_size=64):
    """
    function to produce minibatches for training
    :param X: input placeholder
    :param Y: mask placeholder
    :param batch_size: size of each batch
    :return:
    minibatches for training
    """
    train_length = len(X)
    num_batches = int(np.floor(train_length / batch_size))
    batches = []
    for i in tqdm(range(num_batches)):
        batch_x = X[i * batch_size: i * batch_size + batch_size]
        batch_y = Y[i * batch_size:i * batch_size + batch_size]
        batch_x = load_img(batch_x)
        batch_y = load_img(batch_y)
        batch_x = batch_x.astype(np.float32)
        batch_y = batch_y.astype(np.float32)
        batches.append([batch_x, batch_y])
    return batches

def mini_batches_clients( X, batch_size=64):
    """
    function to produce minibatches for training
    :param X: input placeholder
    :param Y: mask placeholder
    :param batch_size: size of each batch
    :return:
    minibatches for training
    """
    train_length = len(X)
    num_batches = int(np.floor(train_length / batch_size))
    batches = []
    for i in tqdm(range(num_batches)):
        batch_x = X[i * batch_size: i * batch_size + batch_size]
        batch_x = load_img(batch_x)
        batch_x = batch_x.astype(np.float32)
        batches.append([batch_x])
    return batches

#load model and data
metrics = [sm.metrics.IOUScore(threshold=0.5),dice_coef,precision,sensitivity,specificity]

# LR = 0.00001
LR = 1e-5
# LR = 1e-6
optim = tf.keras.optimizers.Adam(LR)
bs=5
no_img = 200
slicing=True

# tf.compat.v1.disable_eager_execution()

client_1 ={}

if slicing == True:
  client_1["original_data"] = mini_batches_(npy_images_path00[:no_img],npy_masks_path00[:no_img],bs)
else:
  client_1["original_data"] = mini_batches_(npy_images_path00,npy_masks_path00,bs)
print("Client 1")
client_1["model"] = unet_s.call()
client_1["optimizer"] =tf.keras.optimizers.Adam(LR)

# import tensorflow as tf


#Losses
dice_loss = sm.losses.DiceLoss()
focal_loss = sm.losses.BinaryFocalLoss()
total_loss = dice_loss + (1 * focal_loss)





print('test data:')
test_data_gen = mini_batches_(npy_images_path00[200:211], npy_masks_path00[200:211],2)

def sum_scaled_weights(scaled_weight_list):
    '''Return the sum of the listed scaled weights. The is equivalent to scaled avg of the weights'''
    avg_grad = list()
    #get the average grad accross all client gradients
    for grad_list_tuple in zip(*scaled_weight_list):
        layer_mean = tf.math.reduce_mean(grad_list_tuple, axis=0)
        avg_grad.append(layer_mean)
    return avg_grad

from matplotlib.pylab import *

import gc
gc.collect()


batch_size=2
steps_per_epoch = 200//batch_size
val_steps_per_epoch = 84//batch_size
iou = sm.metrics.IOUScore(threshold=0.5)
epochs = 120
batch_size= bs
past_model = None
temperature = 0.5
mu = 1

# pre_weight = "/content/drive/MyDrive/VDI/saved_weights/weights_epoch50_final64.h5"
pre_weight = "/content/drive/MyDrive/VDI/saved_weights/64weights/data200scratch22weights_epoch100_final64___IITB.h5" #"/content/drive/MyDrive/VDI/saved_weights/checkpoints/checkpoint_fulldata.h5" #"/content/drive/MyDrive/VDI/saved_weights/weights_epoch50_final22_iitB.h5.h5"
client_1['past_model'] = tf.keras.models.load_model(pre_weight)

# content = "data200scratch22"

checkpoint_path = "/content/drive/MyDrive/VDI/saved_weights/checkpoints/"

dice_loss = sm.losses.DiceLoss()
focal_loss = sm.losses.BinaryFocalLoss()
total_loss = dice_loss + (1 * focal_loss)

dice_coee=[]
contrastv_loss=[]
cl_pe_val = []
dc_pe_val = []
dl_pe_val = []

i = 1
local_weight_list = list()

cp_callback = tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_path,save_weights_only=True,verbose=1)

i += 1
model = client_1['model']
# model.set_weights(pre_weight)
# model = tf.keras.models.load_model(pre_weight)
model = client_1['past_model']

# model.set_weights(client_1['model'].get_weights())

optimizer = client_1['optimizer']
client_loss = []
for epoch in range(epochs):

    print('\nEpoch ', epoch+1)

    for batch_idx, (image, target) in enumerate(tqdm(client_1['original_data'])):

        # print(image.shape)
        pro2, _ = client_1['model'](image)
        # print('pro2------------>\n',pro2)
        # print('_ ------------>\n',_)

        with tf.GradientTape() as tape:

            pro1, output = model(image)
            # print('pro1------------>\n',pro1)
            # print('output------------>\n',output)

            if 'past_model' not in client_1:
                pro3 = tf.zeros_like(pro1)
                past = tf.zeros_like(output)
                # print('if pro3')
                # print('pro3------------>\n',pro3)
                # print('past------------>\n',past)
            else:
                # print('else pro3')
                past_model = client_1['past_model']
                pro3, past = past_model(image)
                # print('pro3------------>\n',pro3)
                # print('past------------>\n',past)

            # cl, lrr = contrastive_loss(past,output,_,0.5,LR)
            cl, lrr = contrastive_loss(pro3,pro1,pro2,0.5,LR)
            # print('--------')
            # print(lrr)
            # LR=LR*lr/LR

            # print(cl)
            loss2 = mu * cl

            loss1 = dice_loss(target, output)
            dc = dice_coef(target, output)
            # print('dice coeff:', dc)

            loss = loss1 + loss2
            client_loss.append(loss)
            # print('dice loss:',loss1, '\ncontrastive loss:', cl)
            dice_coee.append(dc)
            contrastv_loss.append(cl)


        grads = tape.gradient(loss, model.trainable_weights)
        optimizer.apply_gradients(zip(grads, model.trainable_variables))
    # printing epoch wise
    dc_val_pe = sum(dice_coee)/len(dice_coee)
    cl_val_pe = sum(contrastv_loss)/len(contrastv_loss)

    # dc_val_pe_ll = []
    # cl_val_pe_ll = []

    # print('------------------')
    print('epoch dice coeff mean:',dc_val_pe)
    print('epoch contrastive loss mean:',cl_val_pe)
    # dc_val_pe_ll.append(dc_val_pe)
    # cl_val_pe_ll.append(cl_val_pe)

    # print('------------------')

    dc_pe_val.append(dc_val_pe)
    cl_pe_val.append(cl_val_pe)
    dl_pe_val.append(1-dc_val_pe)

    # model.save("/content/drive/MyDrive/VDI/saved_weights/64weights/" + content + "weights_epoch100_final64___IITB" + ".h5")

    dice_coee.clear()
    contrastv_loss.clear()

client_loss = np.array(client_loss).mean()
# print('------------------')
print('\model loss: ', client_loss,'\n')
print('overall per epoch dice coeff mean:',sum(dc_pe_val)/len(dc_pe_val))
print('overall per epoch contrastive loss mean:',sum(cl_pe_val)/len(cl_pe_val))
# print('------------------')

plt.figure()
plt.plot(dc_pe_val)
plt.plot(dl_pe_val)
# plt.lege

client_1['past_model'] = model
client_1['model'] = model
local_weight_list.append(client_1['model'].get_weights())
# model.save("/content/drive/MyDrive/VDI/saved_weights/64weights/" + content + "weights_epoch100_final64___IITB" + ".h5")

# train and adjust weights
print('\Finalizing weights.....\n')
final_model = client_1['model']
CE_loss = tf.keras.losses.CategoricalCrossentropy()
optimizer = client_1['optimizer']
# final_model.set_weights(final_model.load(pre_weight))
average_weights = sum_scaled_weights(local_weight_list)
final_model.set_weights(average_weights)



CE_loss = tf.keras.losses.CategoricalCrossentropy()

dice = []
pre = []
batch_loss=[]
se=[]
spe = []
io = []

model = client_1["model"]

for batch_idx, (images, masks) in enumerate(tqdm(test_data_gen)):
    _, logits = model(images)
    loss = total_loss(masks,logits)
    print('^^^^^^^^^^^^^^^^^^^^^^^666666')
    print(total_loss)
    batch_loss.append(loss)
    #metrics
    dice.append(dice_coef(masks,logits))
    pre.append(precision(masks,logits))
    se.append(sensitivity(masks,logits))
    spe.append(specificity(masks,logits))
    io.append(iou(masks,logits))

    # plt.figure(figsize=(10, 10))
    # plt.subplot(1, 2, 1)
    # plt.imshow(images[:, :, images.shape[2] // 2, 0], cmap='gray')
    # plt.title('Image')


batch_loss = np.array(batch_loss).mean()
dice = np.array(dice).mean()
pre = np.array(pre).mean()
se =  np.array(se).mean()
spe =  np.array(spe).mean()
io =  np.array(io).mean()

print('test results:')
print("Loss: {} , Dice Coeff: {}\n\n, Precision: {} Sensitivity: {} \n\n Specificity: {} , IOU: {}".format(batch_loss,dice,pre,se,spe,io))



# model.save("/content/drive/MyDrive/VDI/saved_weights/" + content + "weights_epoch50_final22_iitB.h5")


model = client_1["model"]
num = 0
path = "/content/drive/MyDrive/VDI/results/"
for batch_idx, (images, masks) in enumerate(test_data_gen):

    test_img = images
    test_mask = masks
    # test_img_input = np.expand_dims(test_img, axis=0)
    test_prediction = model.predict(test_img)
    # test_prediction = test_prediction[0,:,:,:,0]
    # test_prediction = np.argmax(test_prediction,axis = 2)

    num += 1


print('DONE!!!')

"""# For testing process only, based on weights saved"""

# %%
def load_img(img_list):
    images=[]
    for i, image_name in enumerate(img_list):
        # print(i)
        # image = nib.load(image_name).get_fdata()
        image = np.load(image_name)
        images.append(image)
    images = np.asarray(images, dtype=np.float32)
    return(images)

npy_images_path00, npy_masks_path00 = shuffle(npy_images_path00,npy_masks_path00)

test_image = np.load(npy_images_path00[0])
print("test image: ",test_image.shape)




"""## 3D-UNet"""

class UNET3D(tf.keras.Model):
    def __init__(self,classes):
        super(UNET3D,self).__init__()
        self.classes = classes
        # self.encoder_rep = None # s

    #helper functions
    def conv3D(self,x,
               filters,
               filter_size,
               activation = 'relu'):
        out = tf.keras.layers.Conv3D(filters,(filter_size,filter_size,filter_size),padding = "same",use_bias=True )(x)
        batch_norm_ = tf.keras.layers.BatchNormalization()(out)
        conv_batch_norm_act = tf.keras.layers.Activation('relu')(batch_norm_)
        return out

    def upsampling3D(self,x,
                     filters,
                     filter_size,
                     stride =2,
                     activation = 'relu'):
        up_out = tf.keras.layers.Conv3DTranspose(filters,(filter_size,filter_size,filter_size),strides = (stride,stride,stride),padding = 'same')(x)
        batch_norm_ = tf.keras.layers.BatchNormalization()(up_out)
        return batch_norm_

    def concatenate(self,x1,x2):
        concat = tf.keras.layers.concatenate([x1,x2])
        return concat

    def max_pool3D(self, x, filter_size,stride, name = None):
        out = tf.keras.layers.MaxPooling3D((filter_size,filter_size,filter_size),strides = stride, name = name)(x)
        return out

    def downconv(self,x,filters, name = None):
        s1 = self.conv3D(x,filters,3)
        s2 = self.conv3D(s1,filters,3)
        return s2

    def upconv(self,x,
               filters,skip_connection):
        e1 = self.upsampling3D(x,filters,6)
        concat = self.concatenate(e1,skip_connection)
        #layer2
        conv1 = self.conv3D(concat,filters,3)
        #layer 3
        conv2 = self.conv3D(conv1,filters,3)
        return conv2

    def call(self):
        #input
        # inputs = tf.keras.layers.Input(shape = (128,128,128,1))
        inputs = tf.keras.layers.Input(shape = (64,64,64,1))
#         inputs = tf.keras.layers.Input(shape = (240,240,160,4))
        #encoder
        # print(inputs.shape)
        d1 = self.downconv(inputs,32)
        # print(d1.shape)
        m1 = self.max_pool3D(d1,filter_size = 2,stride = 2)
        # print(m1.shape)
        d2 = self.downconv(m1,64)
        m2 = self.max_pool3D(d2,filter_size = 2,stride = 2)
        d3 = self.downconv(m2,128)
        m3 = self.max_pool3D(d3,filter_size = 2,stride = 2)
        d4 = self.downconv(m3,256)
        m4 = self.max_pool3D(d4,filter_size =2,stride=2, name = "layer_before_output")
        # encoder_output = m4
        # print(encoder_output.shape)

        #bottleneck
        bridge1 = self.conv3D(m4,1024,3,1)
        bridge2 = self.conv3D(bridge1,1024,3,1)
        # self.encoder_rep = bridge # s

        #decoder
        # print("bridge2_shape = ",bridge2.shape)
        # print("d4_shape = ",d4.shape)
        u1 = self.upconv(bridge2,256,d4)
        u2 = self.upconv(u1,128,d3)
        u3 = self.upconv(u2,64,d2)
        u4 = self.upconv(u3,32,d1)

        #1x1 output
        logits = tf.keras.layers.Conv3D(self.classes,(1,1,1),padding = "same")(u4)
        logits = tf.nn.sigmoid(logits)

        #model
        model = tf.keras.Model(inputs = [inputs],outputs = [bridge2, logits])
        return model

unet_s = UNET3D(1)

class UNET3DClients(tf.keras.Model):
    def __init__(self,classes):
        super(UNET3DClients,self).__init__()
        self.classes = classes

    #helper functions
    def conv3D(self,x,
               filters,
               filter_size,
               activation = 'relu',name = None):
        out = tf.keras.layers.Conv3D(filters,(filter_size,filter_size,filter_size),padding = "same",name =name,use_bias = True)(x)
        batch_norm_ = tf.keras.layers.BatchNormalization()(out)
        conv_batch_norm_act = tf.keras.layers.Activation('relu')(batch_norm_)
        return out

    def upsampling3D(self,x,
                     filters,
                     filter_size,
                     stride =2,
                     activation = 'relu'):
        up_out = tf.keras.layers.Conv3DTranspose(filters,(filter_size,filter_size,filter_size),strides = (stride,stride,stride),padding = 'same')(x)
        batch_norm_ = tf.keras.layers.BatchNormalization()(up_out)
        return batch_norm_

    def concatenate(self,x1,x2):
        concat = tf.keras.layers.concatenate([x1,x2])
        return concat

    def max_pool3D(self, x, filter_size,stride, name = None):
        out = tf.keras.layers.MaxPooling3D((filter_size,filter_size,filter_size),strides = stride, name = name)(x)
        return out

    def downconv(self,x,filters,name = None):
        s1 = self.conv3D(x,filters,3, name =name )
        s2 = self.conv3D(s1,filters,3, name = name + "0")
        return s2

    def call(self):
        #input
        # inputse = tf.keras.layers.Input(shape = (128,128,128,1))
        inputse = tf.keras.layers.Input(shape = (64,64,64,1))
        #encoder
        d1e = self.downconv(inputse,32, name = "layer1")
        m1e = self.max_pool3D(d1e,filter_size = 2,stride = 2)
        d2e = self.downconv(m1e,64,  name = "layer2")
        m2e = self.max_pool3D(d2e,filter_size = 2,stride = 2)
        d3e = self.downconv(m2e,128, name = "layer3")
        m3e = self.max_pool3D(d3e,filter_size = 2,stride = 2)
        d4e = self.downconv(m3e,256, name = "layer4")
        m4e = self.max_pool3D(d4e,filter_size =2,stride=2)

        #model
        modele = tf.keras.Model(inputs = [inputse],outputs = [m4e])
        return modele
client_unet = UNET3DClients(1)

#dice Coeff
def dice_coef(y_true, y_pred, smooth=1.0):

    smooth = 1.0
    intersection = tf.reduce_sum(y_true * y_pred)
    union = tf.reduce_sum(y_true) + tf.reduce_sum(y_pred)
    dice = (2.0 * intersection + smooth) / (union + smooth)
    return dice

# Computing Precision
def precision(y_true, y_pred):

    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))
    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))
    precision = true_positives / (predicted_positives + K.epsilon())

    return precision

# Computing Sensitivity
def sensitivity(y_true, y_pred):

    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))
    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))

    return true_positives / (possible_positives + K.epsilon())

# Computing Specificity
def specificity(y_true, y_pred):

    true_negatives = K.sum(K.round(K.clip((1-y_true) * (1-y_pred), 0, 1)))
    possible_negatives = K.sum(K.round(K.clip(1-y_true, 0, 1)))

    return true_negatives / (possible_negatives + K.epsilon())

def mini_batches_( X, Y, batch_size=64):
    """
    function to produce minibatches for training
    :param X: input placeholder
    :param Y: mask placeholder
    :param batch_size: size of each batch
    :return:
    minibatches for training
    """
    train_length = len(X)
    num_batches = int(np.floor(train_length / batch_size))
    batches = []
    for i in tqdm(range(num_batches)):
        batch_x = X[i * batch_size: i * batch_size + batch_size]
        batch_y = Y[i * batch_size:i * batch_size + batch_size]
        batch_x = load_img(batch_x)
        batch_y = load_img(batch_y)
        batch_x = batch_x.astype(np.float32)
        batch_y = batch_y.astype(np.float32)
        batches.append([batch_x, batch_y])
    return batches

def mini_batches_clients( X, batch_size=64):
    """
    function to produce minibatches for training
    :param X: input placeholder
    :param Y: mask placeholder
    :param batch_size: size of each batch
    :return:
    minibatches for training
    """
    train_length = len(X)
    num_batches = int(np.floor(train_length / batch_size))
    batches = []
    for i in tqdm(range(num_batches)):
        batch_x = X[i * batch_size: i * batch_size + batch_size]
        batch_x = load_img(batch_x)
        batch_x = batch_x.astype(np.float32)
        batches.append([batch_x])
    return batches

#load model and data
metrics = [sm.metrics.IOUScore(threshold=0.5),dice_coef,precision,sensitivity,specificity]

# LR = 0.00001
LR = 1e-5
# LR = 1e-6
optim = tf.keras.optimizers.Adam(LR)
bs=5
no_img = 200
slicing=True

# tf.compat.v1.disable_eager_execution()

client_1 ={}

if slicing == True:
  client_1["original_data"] = mini_batches_(npy_images_path00[:no_img],npy_masks_path00[:no_img],bs)
else:
  client_1["original_data"] = mini_batches_(npy_images_path00,npy_masks_path00,bs)
print("Client 1")
client_1["model"] = unet_s.call()
client_1["optimizer"] =tf.keras.optimizers.Adam(LR)

# import tensorflow as tf


#Losses
dice_loss = sm.losses.DiceLoss()
focal_loss = sm.losses.BinaryFocalLoss()
total_loss = dice_loss + (1 * focal_loss)





print('test data:')
test_data_gen = mini_batches_(npy_images_path00[200:211], npy_masks_path00[200:211],2)

def sum_scaled_weights(scaled_weight_list):
    '''Return the sum of the listed scaled weights. The is equivalent to scaled avg of the weights'''
    avg_grad = list()
    #get the average grad accross all client gradients
    for grad_list_tuple in zip(*scaled_weight_list):
        layer_mean = tf.math.reduce_mean(grad_list_tuple, axis=0)
        avg_grad.append(layer_mean)
    return avg_grad

from matplotlib.pylab import *

import gc
gc.collect()


batch_size=2
steps_per_epoch = 200//batch_size
val_steps_per_epoch = 84//batch_size
iou = sm.metrics.IOUScore(threshold=0.5)
epochs = 120
batch_size= bs
past_model = None
temperature = 0.5
mu = 1


dice_loss = sm.losses.DiceLoss()
focal_loss = sm.losses.BinaryFocalLoss()
total_loss = dice_loss + (1 * focal_loss)

dice_coee=[]
contrastv_loss=[]
cl_pe_val = []
dc_pe_val = []
dl_pe_val = []

i = 1
local_weight_list = list()

cp_callback = tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_path,save_weights_only=True,verbose=1)

i += 1


# model.set_weights(client_1['model'].get_weights())

# pre_weight = "/content/drive/MyDrive/VDI/saved_weights/weights_epoch50_final64.h5"
# pre_weight = "/content/drive/MyDrive/VDI/saved_weights/64weights/data200scratch22weights_epoch100_final64___IITB.h5" #200 epoch run
# pre_weight = "/content/drive/MyDrive/VDI/saved_weights/64weights/data200scratchweights_epoch100_final64___IITB.h5" ## 100 epoch run
pre_weight = "/content/drive/MyDrive/VDI/saved_weights/64weights/fill/data300_scratchweights_epoch100_final64___IITB_fulldata.h5" #300 runs
client_1['past_model'] = tf.keras.models.load_model(pre_weight)

# content = "data200scratch22"

# checkpoint_path = "/content/drive/MyDrive/VDI/saved_weights/checkpoints/"

model = client_1['model']
# model.set_weights(pre_weight)
model = tf.keras.models.load_model(pre_weight)

dice = []
pre = []
batch_loss=[]
se=[]
spe = []
io = []

test_start = 400
test_data_gen = mini_batches_(npy_images_path00[test_start:test_start+40], npy_masks_path00[test_start:test_start+40],10)

for batch_idx, (images, masks) in enumerate(tqdm(test_data_gen)):
    _, logits = model.predict(images)
    # _, logits = model(images)
    loss = total_loss(masks,logits)
    batch_loss.append(loss)
    #metrics
    dice.append(dice_coef(masks,logits))
    pre.append(precision(masks,logits))
    se.append(sensitivity(masks,logits))
    spe.append(specificity(masks,logits))
    io.append(iou(masks,logits))

    # print("Loss: {} , Dice Coeff: {}\n\n, Precision: {} Sensitivity: {} \n\n Specificity: {} , IOU: {}".format(loss,dice,pre,se,spe,io))

    # plt.figure(figsize=(10, 10))
    # plt.subplot(1, 2, 1)
    # plt.imshow(images[:, :, images.shape[2] // 2, 0], cmap='gray')
    # plt.title('Image')


batch_loss = np.array(batch_loss).mean()
dice = np.array(dice).mean()
pre = np.array(pre).mean()
se =  np.array(se).mean()
spe =  np.array(spe).mean()
io =  np.array(io).mean()

print('test results:')
print("Loss: {} , Dice Coeff: {}\n\n, Precision: {} Sensitivity: {} \n\n Specificity: {} , IOU: {}".format(batch_loss,dice,pre,se,spe,io))

# img=[]
# for batch_idx, (images, masks) in enumerate(tqdm(test_data_gen)):
#   img.append(images)
# _, logits = model.predict(img)



# test_data_gen = mini_batches_(npy_images_path00[100:111], npy_masks_path00[100:111],10)

# for batch_idx, (images, masks) in enumerate(tqdm(test_data_gen)):
#     _, logits = model(images)
#     loss = total_loss(masks,logits)
#     print('^^^^^^^^^^^^^^^^^^^^^^^666666')
#     # print(total_loss)
#     # batch_loss.append(loss)
#     #metrics
#     # dice.append(dice_coef(masks,logits))
#     # pre.append(precision(masks,logits))
#     # se.append(sensitivity(masks,logits))
#     # spe.append(specificity(masks,logits))
#     # io.append(iou(masks,logits))
#     # print(images.shape)
#     # plt.figure(figsize=(10, 10))
#     # plt.subplot(1, 2, 1)
#     # plt.imshow(images[:, :, images.shape[2] // 2, 0], cmap='gray')
#     # plt.title('Image')


# # batch_loss = np.array(batch_loss).mean()
# # dice = np.array(dice).mean()
# # pre = np.array(pre).mean()
# # se =  np.array(se).mean()
# # spe =  np.array(spe).mean()
# # io =  np.array(io).mean()

# # print('test results:')
# # print("Loss: {} , Dice Coeff: {}\n\n, Precision: {} Sensitivity: {} \n\n Specificity: {} , IOU: {}".format(batch_loss,dice,pre,se,spe,io))



# # model.save("/content/drive/MyDrive/VDI/saved_weights/" + "weights_epoch50_final22_iitB.h5")


# # model = client_1["model"]
# # num = 0
# # path = "/content/drive/MyDrive/VDI/results/"
# for batch_idx, (images, masks) in enumerate(test_data_gen):

#     test_img = images
#     test_mask = masks
#     # test_img_input = np.expand_dims(test_img, axis=0)
#     test_prediction = np.array(model.predict(test_img))

#     # print(len(test_prediction))
#     test_prediction = test_prediction[0,:,:,:,0]
#     test_prediction = np.argmax(test_prediction,axis = 2)

#     print(images.shape)
#     plt.figure(figsize=(10, 10))
#     plt.subplot(1, 2, 1)
#     plt.imshow(images[:, :, images.shape[2] // 2, 0], cmap='gray')
#     plt.title('Image')


#     print(images.shape)
#     plt.figure(figsize=(10, 10))
#     plt.subplot(1, 2, 1)
#     plt.imshow(images[:, :, images.shape[2] // 2, 0], cmap='gray')
#     plt.title('Image')

#     num += 1


# # print('DONE!!!')

"""Creates a criterion to measure Dice loss:

    .. math:: L(precision, recall) = 1 - (1 + \beta^2) \frac{precision \cdot recall}
        {\beta^2 \cdot precision + recall}

    The formula in terms of *Type I* and *Type II* errors:

    .. math:: L(tp, fp, fn) = \frac{(1 + \beta^2) \cdot tp} {(1 + \beta^2) \cdot fp + \beta^2 \cdot fn + fp}

    where:
         - tp - true positives;
         - fp - false positives;
         - fn - false negatives;

    Args:
        beta: Float or integer coefficient for precision and recall balance.
        class_weights: Array (``np.array``) of class weights (``len(weights) = num_classes``).
        class_indexes: Optional integer or list of integers, classes to consider, if ``None`` all classes are used.
        per_image: If ``True`` loss is calculated for each image in batch and then averaged,
        else loss is calculated for the whole batch.
        smooth: Value to avoid division by zero.

    Returns:
        A callable ``dice_loss`` instance. Can be used in ``model.compile(...)`` function`
        or combined with other losses.

    Example:

    .. code:: python

        loss = DiceLoss()
        model.compile('SGD', loss=loss)
    """

# def contrastive_loss(z_prev,z_present,z_serv,margin = 0.2, lr=1e-3):
#     #  z_prev = multivariate_norm(z_prev, z_serv)
#     #  z_present = multivariate_norm(z_present, z_serv)
#     # print(z_serv)
#      z_prev = tf.math.l2_normalize(z_prev)
#      z_present = tf.math.l2_normalize(z_present)
#      dis = tf.sqrt(tf.reduce_sum(tf.square(z_present - z_prev)))
#      dis = tf.sqrt(tf.math.maximum(dis, tf.keras.backend.epsilon())) # tf.keras.backend.epsilon()==1e-07
#      sqpres = tf.math.square(z_present)
#      sqMar = tf.math.square(tf.math.maximum(margin - z_present,0))
#      loss = tf.math.reduce_mean(z_prev*sqpres + (1-z_prev)*sqMar)
#      loss = loss - (loss*lr)
#      lr = triplate_mean_lr(z_prev,z_present,z_serv,lr)
#      srv = tf.sqrt(tf.reduce_sum(tf.square(z_serv)))
#      #srv = tf.math.l2_normalize(srv)
#      srv = tf.math.log(srv)
#      return loss/srv

plt.figure(figsize=(15, 5 * len(image_files)))

for i, image_file in enumerate(image_files):
    # Load the 3D numpy image
    image_path = os.path.join(data_dir, image_file)
    numpy_image = np.load(image_path)

    # Load the corresponding ground truth mask
    mask_file = image_file.replace('img_', 'mask_')
    mask_path = os.path.join(mask_dir, mask_file)
    ground_truth_mask = np.load(mask_path)

    # Assuming numpy_image is of shape (128, 128, 128, 3) for color images
    # Assuming ground_truth_mask is of shape (128, 128, 128)

    # Create axial slice for visualization
    z_slice = 64  # Slice along Z-axis (axial)

    # Ensure the slice is within bounds
    z_slice = np.clip(z_slice, 0, numpy_image.shape[2] - 1)

    # Prepare the image for prediction
    test_img_input = np.expand_dims(numpy_image, axis=0)

    # Predict using the loaded model
    test_prediction_slices = model.predict(test_img_input)

    # Assuming test_prediction_slices is a list of 3D arrays, where each array is (1, H, W, D, C)

    # Extract the entire 3D prediction volume
    test_prediction = test_prediction_slices[0][0, :, :, :, 0]

    plt.subplot(len(image_files), 3, i*3 + 1)
    plt.title(f'Test Image - Axial Slice (#{i+1})')
    plt.imshow(test_img_input[0, :, :, z_slice, :])
    plt.axis('off')

    plt.subplot(len(image_files), 3, i*3 + 2)
    plt.title(f'Ground Truth Mask - Axial Slice (#{i+1})')
    plt.imshow(ground_truth_mask[:, :, z_slice], cmap='gray')
    plt.axis('off')

    plt.subplot(len(image_files), 3, i*3 + 3)
    plt.title(f'Prediction - Axial Slice (#{i+1})')
    plt.imshow(numpy_image[:, :, z_slice, :])
    if z_slice < test_prediction.shape[2]:
        plt.imshow(test_prediction[:, :, z_slice], alpha=0.3, cmap='Blues')  # Overlay prediction
    if z_slice < ground_truth_mask.shape[2]:
        plt.imshow(ground_truth_mask[:, :, z_slice], alpha=0.3, cmap='Reds')  # Overlay ground truth mask
    plt.axis('off')

plt.tight_layout()
plt.show()